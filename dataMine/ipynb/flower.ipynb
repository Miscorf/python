{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\n",
    "、\n",
    "手写数字识别器\n",
    "通过\n",
    "MNIST\n",
    "数据集训练得到一个手写数字分类器。要求设计一个至\n",
    "少包含\n",
    "2\n",
    "个卷积层和池化层的卷积神经网络。卷积核的尺寸不小于\n",
    "5*5\n",
    "，\n",
    "要求训\n",
    "后的得到的网络在测试集确率不低于\n",
    "96%\n",
    "（\n",
    "要求在网络中使用\n",
    "dropout\n",
    "）\n",
    "2\n",
    "、\n",
    "CIFAR-10\n",
    "分类网络\n",
    "通过\n",
    "CIFAR-10\n",
    "数据集训练得到一个彩色图像分类网络。要求设计一\n",
    "个至少包含\n",
    "5\n",
    "个卷积层和池化层的卷积神经网络。卷积核的尺寸统一采用\n",
    "3*3\n",
    "，\n",
    "要求训后的得到的网络在测试集上的准确率不低于\n",
    "70%\n",
    "（\n",
    "要求在网络中使用\n",
    "BatchNorm\n",
    "）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species\n",
      "0             1           5.1          3.5           1.4          0.2        0\n",
      "1             2           4.9          3.0           1.4          0.2        0\n",
      "2             3           4.7          3.2           1.3          0.2        0\n",
      "3             4           4.6          3.1           1.5          0.2        0\n",
      "4             5           5.0          3.6           1.4          0.2        0\n",
      "5             6           5.4          3.9           1.7          0.4        0\n",
      "6             7           4.6          3.4           1.4          0.3        0\n",
      "7             8           5.0          3.4           1.5          0.2        0\n",
      "8             9           4.4          2.9           1.4          0.2        0\n",
      "9            10           4.9          3.1           1.5          0.1        0\n",
      "10           11           5.4          3.7           1.5          0.2        0\n",
      "11           12           4.8          3.4           1.6          0.2        0\n",
      "12           13           4.8          3.0           1.4          0.1        0\n",
      "13           14           4.3          3.0           1.1          0.1        0\n",
      "14           15           5.8          4.0           1.2          0.2        0\n",
      "15           16           5.7          4.4           1.5          0.4        0\n",
      "16           17           5.4          3.9           1.3          0.4        0\n",
      "17           18           5.1          3.5           1.4          0.3        0\n",
      "18           19           5.7          3.8           1.7          0.3        0\n",
      "19           20           5.1          3.8           1.5          0.3        0\n",
      "20           21           5.4          3.4           1.7          0.2        0\n",
      "21           22           5.1          3.7           1.5          0.4        0\n",
      "22           23           4.6          3.6           1.0          0.2        0\n",
      "23           24           5.1          3.3           1.7          0.5        0\n",
      "24           25           4.8          3.4           1.9          0.2        0\n",
      "25           26           5.0          3.0           1.6          0.2        0\n",
      "26           27           5.0          3.4           1.6          0.4        0\n",
      "27           28           5.2          3.5           1.5          0.2        0\n",
      "28           29           5.2          3.4           1.4          0.2        0\n",
      "29           30           4.7          3.2           1.6          0.2        0\n",
      "..          ...           ...          ...           ...          ...      ...\n",
      "120         121           6.9          3.2           5.7          2.3        2\n",
      "121         122           5.6          2.8           4.9          2.0        2\n",
      "122         123           7.7          2.8           6.7          2.0        2\n",
      "123         124           6.3          2.7           4.9          1.8        2\n",
      "124         125           6.7          3.3           5.7          2.1        2\n",
      "125         126           7.2          3.2           6.0          1.8        2\n",
      "126         127           6.2          2.8           4.8          1.8        2\n",
      "127         128           6.1          3.0           4.9          1.8        2\n",
      "128         129           6.4          2.8           5.6          2.1        2\n",
      "129         130           7.2          3.0           5.8          1.6        2\n",
      "130         131           7.4          2.8           6.1          1.9        2\n",
      "131         132           7.9          3.8           6.4          2.0        2\n",
      "132         133           6.4          2.8           5.6          2.2        2\n",
      "133         134           6.3          2.8           5.1          1.5        2\n",
      "134         135           6.1          2.6           5.6          1.4        2\n",
      "135         136           7.7          3.0           6.1          2.3        2\n",
      "136         137           6.3          3.4           5.6          2.4        2\n",
      "137         138           6.4          3.1           5.5          1.8        2\n",
      "138         139           6.0          3.0           4.8          1.8        2\n",
      "139         140           6.9          3.1           5.4          2.1        2\n",
      "140         141           6.7          3.1           5.6          2.4        2\n",
      "141         142           6.9          3.1           5.1          2.3        2\n",
      "142         143           5.8          2.7           5.1          1.9        2\n",
      "143         144           6.8          3.2           5.9          2.3        2\n",
      "144         145           6.7          3.3           5.7          2.5        2\n",
      "145         146           6.7          3.0           5.2          2.3        2\n",
      "146         147           6.3          2.5           5.0          1.9        2\n",
      "147         148           6.5          3.0           5.2          2.0        2\n",
      "148         149           6.2          3.4           5.4          2.3        2\n",
      "149         150           5.9          3.0           5.1          1.8        2\n",
      "\n",
      "[150 rows x 6 columns]\n",
      "tensor(1.0724, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.3768, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.3988, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.1178, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.0366, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.1468, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.2228, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.0241, grad_fn=<NllLossBackward0>)\n",
      "0.1\n",
      "tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
      "0.05\n",
      "tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0323, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.2312, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0298, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.2642, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0167, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.2335, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0164, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.1098, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0399, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0808, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0660, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0456, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.1091, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0526, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0846, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0384, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0288, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0796, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.1835, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0640, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0853, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0956, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0350, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0088, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0180, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0609, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0946, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0120, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.1084, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0618, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0364, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0441, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0287, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0403, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0538, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0174, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0706, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.1021, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0299, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0105, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0145, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0157, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0261, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0724, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.1021, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0129, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0663, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.1147, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "0.025\n",
      "tensor([1, 0, 1, 1, 0, 2, 0, 2])\n",
      "tensor([1, 0, 1, 1, 0, 2, 0, 2]) \n",
      "\n",
      "tensor([1, 1, 1, 1, 1, 2, 0, 2])\n",
      "tensor([1, 1, 1, 1, 1, 2, 0, 2]) \n",
      "\n",
      "tensor([1, 0, 2, 1, 2, 0, 0, 2])\n",
      "tensor([1, 0, 2, 1, 2, 0, 0, 2]) \n",
      "\n",
      "tensor([0, 2, 1, 0, 1, 2, 2, 2])\n",
      "tensor([0, 2, 1, 0, 1, 2, 2, 2]) \n",
      "\n",
      "tensor(32) 32 tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset,DataLoader, TensorDataset \n",
    "from sklearn.utils import shuffle \n",
    "import matplotlib. pyplot as plt\n",
    "data=pd.read_csv(\"D:\\Mis\\project\\python\\dataMine\\data\\iris.csv\")\n",
    "for i in range(len(data)):\n",
    "    if data.loc[i,\"Species\"]==\"setosa\":\n",
    "        data.loc[i,\"Species\"]=0\n",
    "    if data.loc[i,\"Species\"]==\"versicolor\":\n",
    "        data.loc[i,\"Species\"]=1\n",
    "    if data.loc[i,\"Species\"]==\"virginica\":\n",
    "        data.loc[i,\"Species\"]=2\n",
    "        \n",
    "print(data)\n",
    "data=data.drop(\"Unnamed: 0\", axis=1)\n",
    "data=shuffle(data) #打散数据 \n",
    "data.index=range(len(data))\n",
    "\n",
    "\n",
    "col_titles=[\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\"]\n",
    "for i in col_titles:\n",
    "    mean,std=data[i].mean(),data[i].std()\n",
    "    data[i]=(data[i]-mean)/std\n",
    "\n",
    "# =====数据集处理==================\n",
    "train_data=data[:-32]\n",
    "train_x=train_data. drop([\"Species\"], axis=1).values #删除Species歹U\n",
    "train_y=train_data[\"Species\"].values.astype(int)\n",
    "train_x=torch.from_numpy(train_x).type(torch.FloatTensor)\n",
    "train_y=torch.from_numpy(train_y).type(torch.LongTensor)\n",
    "test_data=data[-32:]\n",
    "test_x=test_data. drop([\"Species\"], axis=1).values #删1 除Species歹!j\n",
    "test_y=test_data[\"Species\"].values.astype(int)\n",
    "test_x=torch. from_numpy(test_x).type(torch. FloatTensor)\n",
    "test_y=torch. from_numpy(test_y).type(torch. LongTensor)\n",
    "train_dataset=TensorDataset(train_x,train_y)\n",
    "test_dataset=TensorDataset(test_x,test_y)\n",
    "train_loader=DataLoader(dataset=train_dataset, batch_size=16, shuffle=True) #训练数据加载器\n",
    "test_loader=DataLoader(dataset=test_dataset, batch_size=8, shuffle=True)#测试数据加载器\n",
    "#==========构建网络========== \n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1=nn.Linear(4, 8)\n",
    "        self.out=nn.Linear(8, 3)\n",
    "    def forward(self,x): \n",
    "        x=self.hidden1(x) \n",
    "        x=F.relu(x) \n",
    "        x=self.out(x) \n",
    "        return x\n",
    "\n",
    "    \n",
    "net=model ()\n",
    "loss_fn=nn.CrossEntropyLoss()   #交叉燧损失函数\n",
    "opt=torch.optim.SGD(net.parameters(),lr=0.1) #优化器,学习率设置为0. 01\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(opt,milestones=[600,700],gamma = 0.5)\n",
    "#========训练============ \n",
    "for epoch in range(1000):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, y=data\n",
    "        pred=net(x)\n",
    "        loss=loss_fn(pred, y)\n",
    "        \n",
    "        opt.zero_grad() \n",
    "        loss.backward()\n",
    "        opt.step ()\n",
    "        scheduler.step()\n",
    "    if (epoch%10==0): \n",
    "        print(loss)\n",
    "        print(opt.state_dict()['param_groups'][0]['lr'])\n",
    "def rightness(pred, labels):\n",
    "    \n",
    "    pred=torch.max(pred.data,1)[1]\n",
    "    rights=pred.eq(labels.data.view_as (pred)).sum() \n",
    "    return rights, len(labels)\n",
    "#=========测试(验证)=========\n",
    "rights=0\n",
    "length=0\n",
    "for i, data in enumerate(test_loader):\n",
    "    x, y=data\n",
    "    pred=net(x)\n",
    "    rights=rights+rightness(pred, y)[0] \n",
    "    length=length+rightness(pred, y)[1] \n",
    "    print(y)\n",
    "    print(torch.max(pred.data, 1)[1],'\\n')\n",
    "print(rights, length, rights/length)\n",
    "\n",
    "# ======计算正确率========== \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca0422c9975e5e7cf4e0d46dbc04b8de393be20f639917ec80eabe195a811ef3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
